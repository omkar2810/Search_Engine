{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "import math\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from Stemmer import Stemmer\n",
    "from spacy.lang.en import English\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['title','infobox','category','body','ref']\n",
    "type_keys = ['t','i','c','b','r','l']\n",
    "inv_index = defaultdict(lambda: defaultdict(lambda : defaultdict(int)))\n",
    "sec_index = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'collapsiblenav', 'odnbweb']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = {}\n",
    "with open('index/tf.txt') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        text = line.split(\"|\")                 # change the delimiter\n",
    "        tf[int(text[0])] = [text[1],int(text[2])]\n",
    "doc_count = len(tf.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp(a):\n",
    "    return int(a.split('.')[0])\n",
    "    \n",
    "def gen_sind(sindex): \n",
    "    sec_index.clear()\n",
    "    with open(sindex,'r') as fil:\n",
    "        fil_lis = fil.readlines()\n",
    "    for fil in fil_lis:\n",
    "        word = fil.split(\"|\")[1]\n",
    "        sec_index.append(word.strip('\\n'))\n",
    "\n",
    "\n",
    "def get_file(word):\n",
    "    ind = bisect.bisect_right(sec_index,word) - 1\n",
    "    return str(ind) + \".txt\"\n",
    "\n",
    "gen_sind('index/sindex.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dict(coded, key):\n",
    "    if coded == '\\n' :\n",
    "        return\n",
    "    typs = re.sub('[0-9]','|',coded)\n",
    "    typs = typs.split('|')\n",
    "    typs = [x for x in typs if x]\n",
    "    \n",
    "    vals = re.sub('[a-z]','|',coded)\n",
    "    vals = vals.split('|')\n",
    "    vals = [int(x) for x in vals if x ]\n",
    "    doc = vals[0]\n",
    "    total = 0\n",
    "    for i in range(1,len(vals)):\n",
    "        inv_index[key][doc][typs[i-1]] = vals[i]\n",
    "        total += vals[i]\n",
    "    inv_index[key][doc]['a'] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_index(folder,sindex,wrd):\n",
    "    file = folder + get_file(wrd)\n",
    "    with open(file) as fil:\n",
    "        lines = fil.readlines()\n",
    "    for line in lines:\n",
    "        text = line.split('|')\n",
    "        word = text[0]\n",
    "        if word != wrd:\n",
    "            continue\n",
    "        for coded in text:\n",
    "            if coded == word:\n",
    "                continue\n",
    "            parse_dict(coded,word)\n",
    "            \n",
    "def form_index(query):\n",
    "    for q in query:\n",
    "        parse_index('index/','sindex.txt',q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "ps = Stemmer('porter')\n",
    "\n",
    "def modify_query(search):\n",
    "    tokens = re.split(r'[^A-Za-z0-9]+',search)\n",
    "    final = []\n",
    "    for token in tokens:\n",
    "        if len(token) == 0 or nlp.vocab[token].is_stop == True:\n",
    "            continue\n",
    "        token = ps.stemWord(token.lower())\n",
    "        final.append(token)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query,field):\n",
    "    query = modify_query(query)\n",
    "    form_index(query)\n",
    "    docs = []\n",
    "    for token in query:\n",
    "        temp = []\n",
    "        for key in inv_index[token].keys():\n",
    "            if inv_index[token][key][field] > 0:\n",
    "                temp.append(int(key))\n",
    "        docs = list(set(docs).union(set(temp)))\n",
    "    docs = list(set(docs))\n",
    "    results = []\n",
    "    for doc in docs:\n",
    "        total = 0\n",
    "        distinct = 0\n",
    "        title_count = 0 \n",
    "        for token in query:\n",
    "            if inv_index[token][doc][field] > 0:\n",
    "                distinct += 1\n",
    "            if inv_index[token][doc]['t'] > 0:\n",
    "                title_count += 1\n",
    "            total += inv_index[token][doc]['a']\n",
    "            idf = math.log(doc_count/len(inv_index[token].keys()))\n",
    "            tfsc = inv_index[token][doc]['a']/tf[doc][1]\n",
    "        if field == 'a':\n",
    "            results.append([[distinct,[title_count,tfsc*idf*total]],doc])\n",
    "        else:\n",
    "            results.append([[distinct,tfsc*idf*total],doc])\n",
    "    results = sorted(results,reverse=True)\n",
    "\n",
    "    if field == 'a':\n",
    "        final_res = []\n",
    "        for i in range(min(10,len(results))):\n",
    "            final_res.append([tf[results[i][1]][0],results[i][0]])\n",
    "    else:\n",
    "        final_res = {}\n",
    "        for i in range(len(results)):\n",
    "            final_res[results[i][1]] = results[i][0][1]\n",
    "    return final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_fquery(queries):\n",
    "    qresults = defaultdict(lambda:{})\n",
    "    docs = set([])\n",
    "    for token in queries:\n",
    "        typ,query = token.split(':')\n",
    "        typ = typ[0]\n",
    "        qresults[typ] = search(query,typ)\n",
    "        for d_id,coun in qresults[typ].items():\n",
    "            docs.add(d_id)\n",
    "            \n",
    "    results = []\n",
    "    for doc in docs:\n",
    "        distinct = 0\n",
    "        total = 0\n",
    "        for typ in qresults.keys():\n",
    "            if doc in qresults[typ].keys():\n",
    "                distinct += 1\n",
    "                total += qresults[typ][doc]\n",
    "        results.append([[distinct,total],doc])\n",
    "    results = sorted(results,reverse=True)\n",
    "    final_res = []\n",
    "    for i in range(min(10,len(results))):\n",
    "        final_res.append([tf[results[i][1]][0],results[i][0]]) \n",
    "    return final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"A Mayor's Life: Governing New York's Gorgeous Mosaic\",\n",
       "  [3, [3, 0.6374749921830389]]],\n",
       " ['1957 New York City mayoral election', [3, [3, 0.06094333374225238]]],\n",
       " ['1961 New York City mayoral election', [3, [3, 0.059796967693063]]],\n",
       " ['1965 New York City mayoral election', [3, [3, 0.05595167765138047]]],\n",
       " ['New Orleans school desegregation crisis', [3, [1, 0.0022385426189111095]]],\n",
       " ['1931 New Year Honours', [3, [1, 0.00037530049018041976]]],\n",
       " ['Wikipedia:Articles for deletion/Kelly McDowell',\n",
       "  [3, [0, 0.042197336888630914]]],\n",
       " ['Moses J. Wentworth', [3, [0, 0.018688558312810785]]],\n",
       " ['List of assassinations in Asia', [3, [0, 0.013580336200548809]]],\n",
       " ['Center on Global Energy Policy', [3, [0, 0.013175214495391085]]]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('new york mayor','a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_query(query):\n",
    "    tokens = query.split(' ')\n",
    "    ans = []\n",
    "    cur = \"\"\n",
    "    for token in tokens:\n",
    "        if ':' in token:\n",
    "            if cur != \"\":\n",
    "                ans.append(cur)\n",
    "            cur = \"\"\n",
    "            temp = token.split(':')\n",
    "            cur += temp[0] +\":\" +temp[1]\n",
    "        else:\n",
    "            cur += \" \" + token\n",
    "    ans.append(cur)\n",
    "    return ans\n",
    "\n",
    "def is_field(query):\n",
    "    for token in query:\n",
    "        text = token.split(\":\")\n",
    "        if text[0] not in fields:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_search(query):\n",
    "    inv_index.clear()\n",
    "    query = \" \".join(query.split())\n",
    "    query = parse_query(query)\n",
    "    if is_field(query):\n",
    "        return exec_fquery(query)\n",
    "    else:\n",
    "        query = \" \".join(query)\n",
    "        return search(query,'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Gandhi Before India', [3, 35.38798129097616]],\n",
       " ['File:Gandhi Before India.jpg', [2, 8.150568624817286]],\n",
       " ['Great Soul: Mahatma Gandhi and His Struggle With India',\n",
       "  [1, 1.9010072594326028]],\n",
       " ['Shakti Prasad', [1, 1.41664281026259]],\n",
       " ['Gandhi Djuna', [1, 1.108920901335685]],\n",
       " ['City Montessori School, Aliganj Branch', [1, 0.9248143424266717]],\n",
       " ['Kalidas Rangalaya', [1, 0.5287569860673464]],\n",
       " ['City Montessori School, Indira Nagar Branch', [1, 0.45711243261165646]],\n",
       " ['Adyaksha', [1, 0.4354824167378913]],\n",
       " ['Whisky Is Risky', [1, 0.3836179810689022]]]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_search('title:gandhi body:arjun infobox:gandhi category:gandhi ref:gandhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
